%! TEX TS-program = xelatex

\documentclass[10pt]{article}
\usepackage[left=1.4in,right=1.4in,bottom=1in,top=1in]{geometry} % set margins
% \usepackage{fontspec} 						%for loading fonts
% fonts
\usepackage{helvet}
% \usepackage[T1]{fontenc}

\usepackage{array}
\newcolumntype{L}[1]{>{\raggedright\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{C}[1]{>{\centering\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}
\newcolumntype{R}[1]{>{\raggedleft\let\newline\\\arraybackslash\hspace{0pt}}m{#1}}

%A Few Useful Packages
\usepackage{marvosym}
\usepackage{fontspec} 					    %for loading fonts
\usepackage{xunicode,xltxtra,url,parskip} 	%other packages for formatting
\RequirePackage{color,graphicx}
\usepackage[usenames,dvipsnames]{xcolor}
% \usepackage[big]{layaureo} 					%better formatting of the A4 page
% an alternative to Layaureo can be ** \usepackage{fullpage} **
% \usepackage{supertabular} 					%for Grades
\usepackage{titlesec}						%custom \section
%Setup hyperref package, and colours for links
\usepackage{hyperref}
\definecolor{linkcolour}{rgb}{0,0.2,0.6}
\hypersetup{colorlinks,breaklinks,urlcolor=linkcolour, linkcolor=linkcolour}
\usepackage{longtable}
\usepackage{supertabular} 				%for Grades

%FONTS
\defaultfontfeatures{Mapping=tex-text}
% \setmainfont[SmallCapsFont = Fontin SmallCaps]{Fontin.otf}
% modified for Karol Kozioł for ShareLaTeX use
% \setmainfont[
% SmallCapsFont = Fontin-SmallCaps.otf,
% BoldFont = Fontin-Bold.otf,
% ItalicFont = Fontin-Italic.otf
% ]
% {Fontin.otf}

% try lato:

\setmainfont[
	% SmallCapsFont = Fontin-SmallCaps.otf,
	BoldFont = Lato-Bold.ttf,
	ItalicFont = Lato-Italic.ttf
]{Lato-Regular.ttf}

\newcommand{\spacing}{\vspace{0.5cm}}

\newcounter{talkcounter}
\setcounter{talkcounter}{1}
\newcommand{\talknum}[0]{[\thetalkcounter]\stepcounter{talkcounter}}

%%%

%CV Sections inspired by:
%http://stefano.italians.nl/archives/26
\titleformat{\section}{\Large\scshape\raggedright}{}{0em}{}[\titlerule]
\titlespacing{\section}{0pt}{3pt}{3pt}
%Tweak a bit the top margin
%\addtolength{\voffset}{-1.3cm}

% TODO: Remove this?
%--------------------BEGIN DOCUMENT----------------------

\begin{document}

%\pagestyle{empty} % non-numbered pages

\font\fb=''[cmr10]'' %for use with \LaTeX command

%--------------------TITLE-------------
\par{\centering
{\Huge Aaron Mishkin} \par \vspace{0.25cm}
{\href{mailto:amishkin@cs.stanford.edu}{amishkin@cs.stanford.edu} \hspace{0.2cm} \href{https://cs.stanford.edu/~amishkin/}{www.cs.stanford.edu/\~{}amishkin/}}
\par}
%--------------------SECTIONS-----------------------------------

\spacing

\section{Research Interests}

\begin{longtable}{L{0.98\linewidth}}
    Optimization for machine learning, gradient-based methods, convergence of
    algorithms, convex liftings, variational analysis of machine learning
    models.
\end{longtable}

\vspace{0.5ex}

\section{Education}
\begin{longtable}
    {R{1.8cm}|p{11cm}}
    \textsc{Current}      & \textbf{PhD in Computer Science}, Stanford University          \\
    { -- \hspace{0.2cm} } & Thesis: \textit{Convex Analysis of Non-Convex Neural Networks} \\
    \textsc{2020}         & \textsc{Advisor:}
    Dr.
    Mert Pilanci                                                                           \\ \multicolumn{2}{c}{} \\ \textsc{2020} & \textbf{MSc in
    Computer Science}, University of British Columbia                                      \\ { -- \hspace{0.2cm} } &
       \textsc{Thesis}: \textit{Interpolation, Growth Conditions, and Stochastic
    Gradient Descent}                                                                      \\ \textsc{2018} & \textsc{Advisor:} Dr.
    Mark Schmidt                                                                           \\ \multicolumn{2}{c}{} \\ \textsc{2018} & \textbf{BSc in
    Computer Science (Honours)}, University of British Columbia                            \\ { --
    \hspace{0.2cm} }      & \textsc{Thesis:} \textit{Limited Memory Methods for
    Variational Inference}                                                                 \\ \textsc{2013} & \textsc{Advisor:} Dr.
       David Poole
\end{longtable}

\spacing

\section{Research Experience}
\begin{longtable}
    {R{1.8cm}|L{11.8cm}}
    \textsc{May - Aug}  & \textbf{Research Intern}, The Voleon Group                                     \\
    2025                & \textsc{Advisors:} Dr. Sahand Negahban and Dr. Deepak Rajan                    \\
                        & {\small Investigated impact estimation in portfolio
            optimization. Received return offer.}
    \\
    \multicolumn{2}{c}{}                                                                                 \\
    \textsc{July - Dec} & \textbf{Visiting PhD Student}, SIERRA Team, Inria                              \\
    2024                & \textsc{Advisor:}
    Dr.  Francis Bach                                                                                    \\
                        & {\small Worked independently on an empirical and
            theoretical investigation of the convergence of gradient
            flows for two-layer ReLU networks with scalar input data.}
    \\
    \multicolumn{2}{c}{}                                                                                 \\
    \textsc{June - Aug} & \textbf{Predoctoral Researcher}, CCM, Flatiron Institute                       \\
    2023                & \textsc{Advisors:}
    Dr.
    Robert Gower and Dr.
    Alberto Bietti                                                                                       \\
                        & {\small
            Led two projects as an intern: one developed new
            convergence bounds for gradient descent under
            directional smoothness (NeurIPS 2024), while the
            other developed practical algorithms and analysis for level set
            teleportation (AISTATS 2025).
    }                                                                                                    \\ \multicolumn{2}{c}{} \\
    \textsc{May - Aug}  & \textbf{Applied Science Intern}, Amazon Development Center Germany             \\
    2019                & \textsc{Advisors:}
    Dr.
    Cédric Archambeau and Dr.
    Matthias Seeger                                                                                      \\
                        & {\small Investigated meta-learning approaches to
            cold-start active learning.
            Implemented foMAML, prototypical networks, and conditional neural
            adaptive processes (CNAPS).
    }                                                                                                    \\ \multicolumn{2}{c}{} \\
    \textsc{Jan - Jun}  & \textbf{Research Intern}, RIKEN Center for Advanced Intelligence Project (AIP) \\
    2018                & \textsc{Advisor:}
    Dr.
    Emtiyaz Khan                                                                                         \\
                        & {\small Co-led development of SLANG, a stochastic,
            approximate natural gradient method for Gaussian
            variational inference in neural networks (NeurIPS 2018).}
\end{longtable}

\newpage

\section{Other Experience}
\begin{longtable}{R{1.8cm}|L{11.8cm}}
    \textsc{May - Aug} & \textbf{Undergraduate Research Assistant}, UBC
    \\ 2016/17 & \textsc{Advisors:} Dr.  David Poole and Dr.
    Giuseppe Carenini                                                       \\
                       & {\small Received two undergraduate research awards
            from NSERC to investigate information visualizations for
            preference elicitation and
            develop \href{http://www.cs.ubc.ca/group/iui/VALUECHARTS/}{Web
                ValueCharts}.  }
    \\
    \multicolumn{2}{c}{}                                                    \\
    \textsc{May - Dec} & \textbf{Software Engineering Co-op Student},
    MacDonald, Dettwiler and Associates                                     \\
    2015
                       & {\small Acted as a full member of a small team to
            develop a client for ordering satellite imagery.
            Implemented the map interface for the RADARSAT
            Constellation Mission.  }
\end{longtable}

\spacing

\section{Awards and Fellowships}

\begin{longtable}
    {R{1.8cm}|L{11.8cm}}
    \multicolumn{2}{c}{\large \textbf{PhD} \hspace{11cm} }                                            \\
    \multicolumn{2}{c}{}                                                                              \\
    2025       & \textbf{Best Poster}                                                                 \\
               & International Conference on Continuous Optimization (ICCOPT)                         \\
               & {\small For ``Directional Smoothness and Gradient Methods:
    Convergence and Adaptivity''. }                                                                   \\
    \multicolumn{2}{c}{}                                                                              \\
    2024       & \textbf{Visiting Student Research Fellowship}                                        \\
               & France-Stanford Center for Interdisciplinary Studies                                 \\
               & {\small  Awarded to support a research visit to the SIERRA
    team at Inria Paris. }                                                                            \\
    \multicolumn{2}{c}{}                                                                              \\
    2020       & \textbf{Graduate Research Fellowship (GRF)}                                          \\
               & National Sciences Foundation (NSF)                                                   \\
               & {\small  Five-year fellowship for PhD students in STEM disciplines. }                \\
    \multicolumn{2}{c}{}                                                                              \\
    2020       & \textbf{Postgraduate Scholarships-Doctoral Program (PGS D)} \hfill                   \\
               & Natural Sciences and Engineering Research Council of Canada (NSERC)                  \\
               & {\small  Three-year fellowship for PhD students studying in Canada or abroad. }      \\
    \multicolumn{2}{c}{}                                                                              \\
    2020       & \textbf{Canada Graduate Scholarships-Doctoral Program (CGS D)} \hfill {(Declined)}   \\
               & Natural Sciences and Engineering Research Council of Canada (NSERC)                  \\
               & {\small  Three-year fellowship for PhD students studying in Canada. }                \\
    \multicolumn{2}{c}{}                                                                              \\
    %%
    \multicolumn{2}{c}{\large \textbf{MSc} \hspace{11cm} }                                            \\
    \multicolumn{2}{c}{}                                                                              \\
    2019       & \textbf{Huawei Graduate Scholarship}                                                 \\
               & Huawei and Department of Computer Science, UBC                                       \\
               & {\small  Competitive scholarship for MSc students entering their second year. }      \\
    \multicolumn{2}{c}{}                                                                              \\
    2018       & \textbf{Computer Science Merit Scholarship}                                          \\
               & Department of Computer Science, UBC                                                  \\
               & {\small  Merit-based scholarship for incoming international and domestic students. } \\
    \multicolumn{2}{c}{}                                                                              \\
    2018       & \textbf{Canada Graduate Scholarships-Master’s Program (CGSM)}                        \\
               & Natural Sciences and Engineering Research Council of Canada (NSERC)                  \\
               & {\small National fellowship awarded to up to 2,500 students annually. }              \\
    \multicolumn{2}{c}{}                                                                              \\
    \multicolumn{2}{c}{}                                                                              \\
    \multicolumn{2}{c}{}                                                                              \\
    \multicolumn{2}{c}{}                                                                              \\
    \multicolumn{2}{c}{\large \textbf{BSc} \hspace{11cm} }                                            \\
    \multicolumn{2}{c}{}                                                                              \\
    2018       & \textbf{Academic Award of Excellence (Honors)}                                       \\
               & Department of Computer Science, UBC                                                  \\
               & {\small Awarded to the graduating student with the highest standing
    in the BSc (Honors) in Computer Science. }                                                        \\
    \multicolumn{2}{c}{}                                                                              \\
    2018       & \textbf{Markus Meister Memorial Prize}                                               \\
               & Department of Computer Science, UBC                                                  \\
               & {\small Awarded to the graduating student with the highest standing
    in the final year of the BSc in Computer Science. }                                               \\
    \multicolumn{2}{c}{}                                                                              \\
    2017       & \textbf{D.
        F.
    MacKenzie Scholarship}                                                                            \\
               & UBC                                                                                  \\
    \multicolumn{2}{c}{}                                                                              \\
    2016, 2017 &
    \textbf{Undergraduate Student Research Award (USRA)}                                              \\
               & Natural Sciences and
    Engineering Research Council of Canada (NSERC)                                                    \\
    \multicolumn{2}{c}{}                                                                              \\
    2016, 2017 &
    \textbf{Computer Science Scholarship}                                                             \\
               & Department of Computer Science, UBC
    \\
    \multicolumn{2}{c}{}                                                                              \\
    2016, 2017 & \textbf{Trek Excellence Scholarship
    for Continuing Students}                                                                          \\
               & UBC                                                                                  \\
               & {\small Awarded to students in the top 5\% of their
    undergraduate year, faculty, and school.  }                                                       \\
    \multicolumn{2}{c}{}                                                                              \\
    2016       & \textbf{J Fred Muir Memorial Scholarship}                                            \\
               & UBC                                                                                  \\
    \multicolumn{2}{c}{}                                                                              \\
    \multicolumn{2}{c}{\large \textbf{General} \hspace{11cm} }                                        \\
    \multicolumn{2}{c}{}                                                                              \\
    2018       & \textbf{Travel Award for NeurIPS 2018}                                               \\
               & Neural Information Processing Systems (NeurIPS) Foundation                           \\
    \multicolumn{2}{c}{}                                                                              \\
    2017       & \textbf{Best Demo}                                                                   \\
               & UBC HCI Designing for People Year-end Event                                          \\
               & {\small For a live demonstration of Web ValueCharts.}
\end{longtable}

\spacing

\section{Publications}

\vspace{1em}

\subsection*{Preprints}

\begin{longtable}{C{0.1\linewidth} L{0.88\linewidth}}
    [FMV] & Curtis Fox, \textbf{Aaron Mishkin}, Sharan Vaswani, Mark Schmidt.  ``Glocal
    Smoothness: Line Search can really help!''
    \href{https://arxiv.org/abs/2506.12648}{[arXiv]}
    \\
    \multicolumn{2}{c}{}
    \\

    [RMS] &
    Amrutha Varshini Ramesh*, \textbf{Aaron Mishkin}*, Mark Schmidt, Yihan
    Zhou, Jonathan Wilder Lavington, and Jennifer She.  ``Analyzing and
    Improving Greedy 2-Coordinate Updates for Equality-Constrained Optimization
    via Steepest Descent in the 1-Norm.''
    \href{https://arxiv.org/abs/2307.01169}{[arXiv]}
    \\
    \multicolumn{2}{c}{}
    \\

    [ZWM] & Emi Zeger, Yifei Wang, \textbf{Aaron Mishkin}, Tolga Ergen, Emmanuel
    Candès, and Mert Pilanci. ``A Library of Mirrors: Deep Neural Nets in Low
    Dimensions are Convex Lasso Models with Reflection Features.''
    \href{https://arxiv.org/abs/2403.01046}{[arXiv]}
\end{longtable}

\subsection*{Refereed Papers}

\begin{longtable}{C{0.1\linewidth} L{0.88\linewidth}}
    [MBG25]     & \textbf{Aaron Mishkin}, Alberto Bietti, Robert Gower. ``Level Set
    Teleportation: An Optimization Perspective''. Artificial Intelligence and
    Statistics (AISTATS), 2025 \href{https://arxiv.org/abs/2403.03362}{[arXiv]}
    \\
    \multicolumn{2}{c}{}                                                                      \\

    [KMP25]     & Sungyoon Kim, \textbf{Aaron Mishkin}, Mert Pilanci. ``Exploring the loss
    landscape of regularized neural networks via convex duality''.
    International Conference on Learning Representations (ICLR), 2025.
    \href{https://arxiv.org/abs/2411.07729}{[arXiv]}
    \\
    \multicolumn{2}{c}{}                                                                      \\

    [MKW24]\!\! & \textbf{Aaron Mishkin}*, Ahmed Khaled*, Yuanhao Wang, Aaron Defazio, Robert
    Gower. ``Directional Smoothness and Gradient Methods: Convergence and
    Adaptivity'' \textit{Neural Information Processing Systems (NeurIPS)},
    2024. \href{https://arxiv.org/abs/2403.04081}{[arXiv]}                                    \\
    \multicolumn{2}{c}{}                                                                      \\

    [MP23]      & \textbf{Aaron Mishkin}, Mert Pilanci. ``Optimal Sets and Solution Paths of
    ReLU Networks'' \textit{International Conference on Machine Learning
        (ICML)}, 2023. \href{https://arxiv.org/abs/2306.00119}{[arXiv]}
    \\
    \multicolumn{2}{c}{}                                                                      \\

    [MSP22]     & \textbf{Aaron Mishkin}, Arda Sahiner, Mert Pilanci. ``Fast Convex
    Optimization for Two-Layer ReLU Networks: Equivalent Model Classes and Cone
    Decompositions'' \textit{International Conference on Machine Learning
    (ICML)}, 2022. \href{https://arxiv.org/abs/2202.01331}{[arXiv]}                           \\
    \multicolumn{2}{c}{}                                                                      \\

    %%
    [VML19]     & Sharan Vaswani, \textbf{Aaron Mishkin}, Issam Laradji, Mark Schmidt,
    Gauthier Gidel, and Simon Lacoste-Julien.  ``Painless Stochastic Gradient:
    Interpolation, Line-Search, and Convergence Rates.'' \textit{Neural
        Information Processing Systems (NeurIPS)}, 2019.
    \href{https://arxiv.org/abs/1905.09997}{[arXiv]}
    \\
    \multicolumn{2}{c}{}                                                                      \\

    %%
    [MKN18]\!\! & \textbf{Aaron Mishkin}, Frederik Kunstner, Didrik Nielsen, Mark Schmidt,
    and Mohammad Emtiyaz Khan. ``SLANG: Fast Structured Covariance
    Approximations for Bayesian Deep Learning with Natural-Gradient'',
    \textit{Neural Information Processing Systems (NeurIPS)}, 2018.
    \href{https://arxiv.org/abs/1811.04504}{[arXiv]}
\end{longtable}

\subsection*{Book Chapters}

\begin{longtable}{C{0.1\linewidth} L{0.88\linewidth}}
    [MKM22]\!\! & Kevin P.  Murphy, Frederik Kunstner, Si Yi Meng, \textbf{Aaron Mishkin},
    Sharan Vaswani, and Mark Schmidt.  \textbf{Chapter 8: Optimization} in
    \textit{Probabilistic Machine Learning: An Introduction}.  MIT press, 2022.
\end{longtable}

\subsection*{Workshop Papers}

\begin{longtable}{C{0.1\linewidth} L{0.88\linewidth}}
    [MKD23]\!\! & \textbf{Aaron Mishkin}*, Ahmed Khaled*, Aaron Defazio, Robert Gower. ``A
    Novel Analysis of Gradient Descent Under Directional Smoothness''
    \textit{NeurIPS OPT2023}, 2023.
    \href{https://opt-ml.org/papers/2023/paper77.pdf}{[pdf]}                                \\
    \multicolumn{2}{c}{}                                                                    \\

    [MBG23]     & \textbf{Aaron Mishkin}, Alberto Bietti, Robert Gower. ``Level Set
    Teleportation: the Good, the Bad, and the Ugly'' \textit{NeurIPS OPT2023},
    2023. \href{https://opt-ml.org/papers/2023/paper35.pdf}{[pdf]}
    \\
    \multicolumn{2}{c}{}                                                                    \\

    [MP22]      & \textbf{Aaron Mishkin}, Mert Pilanci. ``The Solution Path of the Group
    Lasso'' \textit{NeurIPS OPT2022}, 2022.
    \href{https://opt-ml.org/papers/2022/paper63.pdf}{[pdf]}
    \\
    \multicolumn{2}{c}{}                                                                    \\

    %%
    [RMS22]     & Amrutha Varshini Ramesh, \textbf{Aaron Mishkin}, Mark Schmidt.  ``Fast
    Convergence of Greedy 2-Coordinate Updates for Optimizing with an Equality
    Constraint'' \textit{NeurIPS OPT2022}, 2022.
    \href{https://opt-ml.org/papers/2022/paper82.pdf}{[pdf]}
    \\
    \multicolumn{2}{c}{}                                                                    \\

    %%
    [VBG20]     & Sharan Vaswani, Reza Babanezhad, Jose Gallego, \textbf{Aaron Mishkin},
    Simon Lacoste-Julien, and Nicolas Le Roux.  ``To Each Optimizer a Norm, to
    Each Norm its Generalization.'' \textit{NeurIPS OPT2020}, 2020.
    \href{https://arxiv.org/abs/2006.06821}{[arXiv]}
    \\
    \multicolumn{2}{c}{}                                                                    \\

    %%
    [M17]       & \textbf{Aaron Mishkin}. ``Web ValueCharts: Analyzing Individual and Group
    Preferences with Interactive, Web-based Visualizations'', Extended Abstract
    in \textit{Review of Undergraduate Computer Science}, 2017.
    \href{https://www.cs.ubc.ca/~amishkin/amishkinVCExtendedAbstract.pdf}{[pdf]}
\end{longtable}
\vspace{-1ex}

* Denotes equal contribution.

\spacing

\section{Presentations}

\vspace{1em}

\subsection*{Contributed and Invited Talks}

\renewcommand{\arraystretch}{0.65}

\begin{longtable}{C{0.05\linewidth} L{0.93\linewidth}}
    \talknum &
    ``Optimal Sets and Solution Paths of ReLU Networks''. SIAM \href{https://siamncc25.lbl.gov}{NCC25},
    October 2025.
    \href{https://github.com/aaronpmishkin/talk-ncc25}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Level Set Teleportation: An Optimization Perspective''. Montreal MLOpt Seminar, January 2025.
    \href{https://github.com/aaronpmishkin/teleport-talk}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Optimal Sets and Solution Paths of ReLU Networks''. EPFL MLO Group, November 2024.
    \href{https://github.com/aaronpmishkin/talk-mml}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Level Set Teleportation: An Optimization Perspective. MPI Intelligent Systems/ELLIS Institute, August 2024.
    \href{https://github.com/aaronpmishkin/teleport-talk}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Optimal Sets and Solution Paths of ReLU Networks''. \href{https://www.mis.mpg.de/events/series/math-machine-learning-seminar-mpi-mis-ucla}{Math Machine Learning Seminar MPI MIS + UCLA}, January 2024.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/amishkin_mml_seminar.pdf}{[slides]}
    \href{https://www.mis.mpg.de/events/event/optimal-sets-and-solution-paths-of-relu-networks}{[video]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``SGD Under Interpolation: Convergence, Line-search, and Acceleration''. \href{https://meetings.siam.org/sess/dsp_programsess.cfm?SESSIONCODE=76238}{SIAM OP23 Minisymposium on Adaptivity in Stochastic Optimization}, June 2023.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/siam_op23_slides.pdf}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Fast Convex Optimization for Two-Layer ReLU Networks. UBC Institute for Applied Mathematics, July 2022.
    \href{https://github.com/aaronpmishkin/talk-iam_seminar_scnn}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates''. Machine Learning Summer School (MLSS) 2020, July 2020 (Virtual).
    \href{https://cs.stanford.edu/~amishkin/assets/slides/painless_mlss_version.pdf}{[slides]}
    \href{https://www.youtube.com/watch?v=IchhE4JXLE4}{[video]}
\end{longtable}

\subsection*{Miscellaneous Talks}

\begin{longtable}{C{0.05\linewidth} L{0.93\linewidth}}
    \talknum &
    ``Instrumental Variables, DeepIV, and Forbidden Regressions: Learning to
    evaluate counterfactuals via instrumental variables.''
    UBC MLRG, Spring 2020.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/instrumental_variables.pdf}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Why Does Deep Learning Work?''
    UBC MLRG, Autumn 2019.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/deep_learning_works.pdf}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Generative Adversarial Networks.''
    UBC MLRG, Spring 2019.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/gans.pdf}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Standard and Natural Policy Gradients for Discounted Rewards.''
    UBC MLRG, Autumn 2019.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/policy_gradients.pdf}{[slides]}
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Web ValueCharts: Exploring Individual and Group Preferences
    Through Interactive Web-based Visualizations.'' CUCSC 2017, Summer 2017.
    \\
    \multicolumn{2}{c}{} \\

    \talknum &
    ``Web ValueCharts: Supporting Decision Makers with Interactive, Web-Based Visualizations.''
    MURC 2017, Spring 2017.
    \href{https://cs.stanford.edu/~amishkin/assets/slides/policy_gradients.pdf}{[slides]}
\end{longtable}

\renewcommand{\arraystretch}{1}

\newpage

\section{Teaching}

\begin{longtable}
    {R{1.8cm}|L{11.8cm}}
    \textsc{Apr - Jun}
     & \textbf{TA}, EE 364B: Convex Optimization II (Stanford University)      \\
    \vspace{0.3cm}2022-2025
     & {\small Prepared homework and exam questions, held weekly office hours,
            and supervised assignment graders for a graduate-level class on convex
    optimization algorithms.}                                                  \\
    \multicolumn{2}{c}{}                                                       \\
    \textsc{ Jun 2018}
     & \textbf{TA}, Data Science Summer School (DS3) 2018                      \\
     & {\small Prepared and delivered exercises on stochastic variational
            inference for graduate students attending a two day tutorial on
    approximate Bayesian inference.}                                           \\
    \multicolumn{2}{c}{}                                                       \\
    \textsc{Sep - Dec}
     & \textbf{TA}, CPSC 340: Machine Learning                          (UBC)  \\
    \vspace{0.7cm} 2017
     & {\small Gave tutorials on diverse topics in machine learning, including
            regularization, convexity, and MAP estimation.  Held weekly office hours
            for students, marked assignments and invigilated exams.  }
    \\
    \multicolumn{2}{c}{}                                                       \\
    \textsc{Jan - May}
     & \textbf{TA}, CPSC 210: Software Construction                     (UBC)  \\
    \vspace{0.2cm}2015
     & {\small Supervised laboratories for a software engineering course on
            object-oriented programming and design in the Java programming language.}
    \\
    \multicolumn{2}{c}{}                                                       \\
    \textsc{Sep - Dec}
     & \textbf{TA}, CPSC 110: Computation, Programs and Programming     (UBC)  \\
    \vspace{0.3cm}2014
     & {\small Taught the fundamental concepts of functional programming in a
            Lisp-family language during weekly labs.}
\end{longtable}

\spacing

%
% \section{Conference Attendence}
% \begin{longtable}{R{1.8cm}|L{11.8cm}}
% 	Dec 2019 & Neural Information Processing Systems (NeurIPS), Vancouver, Canada. \\ & {\small \textbf{Poster:} \textit{Painless Stochastic Gradient: Interpolation, Line-Search, and Convergence Rates}}\\ \multicolumn{2}{c}{} \\
% 	Aug 2019 & International Conference on Continuous Optimization (ICCOPT), Berlin, Germany. \\ \multicolumn{2}{c}{} \\
% 	Dec 2018 & Neural Information Processing Systems (NeurIPS), Montreal, Canada. \\ & {\small \textbf{Poster:} \textit{SLANG: Fast Structured Covariance Approximations for Bayesian Deep Learning with Natural Gradient}}\\ \multicolumn{2}{c}{} \\
% 	% Sep 2017 & Undergraduate Research Opportunities Conference, Waterloo, Canada. \\ \multicolumn{2}{c}{} \\
% 	Jun 2017 & Canadian Undergraduate Computer Science Conference, Toronto, Canada. \\ & {\small \textbf{Talk:} \textit{Web ValueCharts: Exploring Individual and Group Preferences through Interactive, Web-based Visualizations}}\\ \multicolumn{2}{c}{} \\
% 	Mar 2017 & Multi-Disciplinary Undergraduate Research Conference, Vancouver, Canada. \\ & {\small \textbf{Talk:} \textit{Web ValueCharts: Supporting Decision Makers with Interactive, Web-based Visualizations}}
% \end{longtable}

\section{Academic Service}

\vspace{1ex}

\textbf{Reviewing}:
NeurIPS, ICML, ICLR, AISTATS, JMLR, TMLR, SIMODS, and IEEE Transactions on Information Theory.

\textbf{Reviewer Awards}: NeurIPS (2020, 2022, 2023, 2025), ICML (2021, 2022,
2024, 2025), ICLR (2022), and AISTATS (2022, 2025).
I have also been a TMLR Expert Reviewer since 2024 and was an ICML Expert Reviewer
in 2021.

\textbf{Mentorship}: I volunteer for the Stanford student application support program (SASP) and
am a mentor for the \href{https://stanfordcsmentoring.com}{Stanford CS
    undergraduate mentorship program} and
Stanford's \href{https://serio.stanford.edu}{SERIO} program.

%\newpage
%\hypertarget{gmat}{\textsc{Gmat}\setmainfont{LMRoman10 Regular}\textregistered\setmainfont[SmallCapsFont=Fontin-SmallCaps]{Fontin-Regular}}

%\XeTeXpdffile ''GMAT.pdf'' page 1 scaled 800

\end{document}
